{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f4ae4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import dlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d48e1e5",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Unable to open shape_predictor_68_face_landmarks.dat",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m detector \u001b[38;5;241m=\u001b[39m dlib\u001b[38;5;241m.\u001b[39mget_frontal_face_detector()\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Загрузите предварительно обученную модель для предсказания точек лица\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m predictor \u001b[38;5;241m=\u001b[39m \u001b[43mdlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape_predictor\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshape_predictor_68_face_landmarks.dat\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Примените детектор лиц к изображению\u001b[39;00m\n\u001b[0;32m     12\u001b[0m faces \u001b[38;5;241m=\u001b[39m detector(gray)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Unable to open shape_predictor_68_face_landmarks.dat"
     ]
    }
   ],
   "source": [
    "image = cv2.imread('pena.png')\n",
    "# Преобразуйте его в черно-белое\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Создайте объект детектора лиц\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "\n",
    "# Загрузите предварительно обученную модель для предсказания точек лица\n",
    "predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n",
    "\n",
    "# Примените детектор лиц к изображению\n",
    "faces = detector(gray)\n",
    "\n",
    "# Если лица обнаружены, создайте контур для каждого лица\n",
    "if len(faces) > 0:\n",
    "    for face in faces:\n",
    "        # Получите точки контура лица\n",
    "        landmarks = predictor(gray, face)\n",
    "        points = np.array([(p.x, p.y) for p in landmarks.parts()])\n",
    "\n",
    "        # Создайте маску для контура лица\n",
    "        mask = np.zeros_like(gray)\n",
    "        cv2.drawContours(mask, [points], 0, (255), -1)\n",
    "\n",
    "        # Примените маску к исходному изображению\n",
    "        masked_image = cv2.bitwise_and(image, image, mask=mask)\n",
    "\n",
    "        cv2.imshow('Masked Image', masked_image)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "else:\n",
    "    print(\"Лица не обнаружены на изображении.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb47de7d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
